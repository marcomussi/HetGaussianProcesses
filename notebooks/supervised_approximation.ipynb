{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b56097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, datetime, json, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import tikzplotlib as tkz\n",
    "\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "print(f\"Current path: {os.getcwd()}\")\n",
    "sys.path.append('./')\n",
    "\n",
    "from supervisedlearning.approximation import ApproximatedHeteroskedasticGaussianProcessRegressorRBF\n",
    "\n",
    "from utils import make_json_serializable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63e0b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_plt = 1000\n",
    "x_plt = np.linspace(0, 1, n_samples_plt)\n",
    "\n",
    "def exp_reward_values(xvect):\n",
    "    return np.cos(xvect * 6.28 - 1)\n",
    "\n",
    "dateformat = \"(%Y-%b-%d %Ih%Mm%p)\"\n",
    "save_path = \"results/supervised/approximation/\"\n",
    "\n",
    "\n",
    "# TESTING THE FITTING QUALITY FOR DIFFERENT KERNEL LENGTHS\n",
    "N_test = 100\n",
    "reg = 0.01\n",
    "x_vect = np.linspace(0, 1, N_test)\n",
    "y_vect = exp_reward_values(x_vect)\n",
    "x_vect = x_vect.reshape(N_test, 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_vect.ravel(), y_vect, \"--\", linewidth=4, label=\"RealFun\")\n",
    "\n",
    "for kernel_L in [10]:\n",
    "\n",
    "    regressor = ApproximatedHeteroskedasticGaussianProcessRegressorRBF(kernel_L, reg)\n",
    "    regressor.load_data(x_vect, y_vect)\n",
    "    y_hat, y_sigma = regressor.compute(x_plt.reshape(-1, 1))\n",
    "    plt.plot(x_plt.ravel(), y_hat, label=f\"L={kernel_L}\")\n",
    "    plt.fill_between(x_plt.ravel(), y_hat - y_sigma, y_hat + y_sigma, alpha=0.3)\n",
    "                \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e65d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kernel_L_lst = [10]\n",
    "epsilon_lst = [None, 0.02, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "regularization_lst = [1, 5, 10, 50, 100, 500, 1000] # for the first two kinds of tests\n",
    "# regularization_lst = [2, 4, 6, 8, 10, 20, 40, 60, 80, 100] # for the last kind of tests\n",
    "N_lst = [200, 400, 600, 800, 1000]\n",
    "\n",
    "assert epsilon_lst[0] is None, \"The first element of epsilon_lst should be None\"\n",
    "results = {}\n",
    "\n",
    "for N in N_lst:\n",
    "    print(f\"Processing N = {N}...\")\n",
    "    results[N] = {}\n",
    "    np.random.seed(0)\n",
    "    x_vect = np.linspace(0, 1, N)\n",
    "    y_vect = exp_reward_values(x_vect)\n",
    "    x_vect = x_vect.reshape(N, 1)\n",
    "        \n",
    "    for kernel_L in kernel_L_lst:\n",
    "        results[N][kernel_L] = {}\n",
    "\n",
    "        for regularization in regularization_lst:\n",
    "            print(f\"    Processing regularization = {regularization}...\")\n",
    "            results[N][kernel_L][regularization] = {}\n",
    "            y_hat, y_sigma = {}, {}\n",
    "\n",
    "            for epsilon in epsilon_lst:\n",
    "                results[N][kernel_L][regularization][epsilon] = {}\n",
    "                regressor = ApproximatedHeteroskedasticGaussianProcessRegressorRBF(kernel_L, regularization, epsilon=epsilon)\n",
    "                regressor.load_data(x_vect, y_vect)\n",
    "                y_hat[epsilon], y_sigma[epsilon] = regressor.compute(x_plt.reshape(-1, 1))\n",
    "                results[N][kernel_L][regularization][epsilon][\"errorinfnorm\"] = np.round(max(np.abs(y_hat[epsilon] - y_hat[None])), 5)\n",
    "                results[N][kernel_L][regularization][epsilon][\"errorinfnormvar\"] = np.round(max(np.abs(y_sigma[epsilon] - y_sigma[None])), 5)\n",
    "                results[N][kernel_L][regularization][epsilon][\"nsample\"] = regressor.cover_x.shape[0] if epsilon is not None else None\n",
    "\n",
    "for N in N_lst:\n",
    "    for kernel_L in kernel_L_lst:\n",
    "        for regularization in regularization_lst:\n",
    "            for epsilon in epsilon_lst:\n",
    "                print(f\"N = {N} - kernel_L = {kernel_L} - $\\lambda$ = {regularization} - $\\epsilon$ = {epsilon} \\t Error = {results[N][kernel_L][regularization][epsilon]['errorinfnorm']}    \\t Cover Size = {results[N][kernel_L][regularization][epsilon]['nsample']}\")\n",
    "\n",
    "serializable_dict = make_json_serializable(results)\n",
    "complete_path_json = f\"{save_path}N{N_lst}_kernelL{kernel_L_lst}_reg{regularization_lst}_eps{epsilon_lst}_{datetime.datetime.now().strftime(dateformat)}.json\"\n",
    "with open(complete_path_json, \"w\", encoding=\"utf-8\") as filejson:\n",
    "    json.dump(serializable_dict, filejson, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a04d26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "\n",
    "N_vect = np.array(N_lst)\n",
    "epsilon_vect = np.array(epsilon_lst[1:])\n",
    "\n",
    "# reg fixed\n",
    "# forall N forall kernel_L\n",
    "# for every lambda plot infnorm-error varying epsilon\n",
    "\n",
    "norm = plt.Normalize(-1, np.log(max(regularization_lst)))\n",
    "cmap = cm.get_cmap(\"viridis_r\")\n",
    "\n",
    "for N in N_lst:\n",
    "    for kernel_L in kernel_L_lst:\n",
    "        plt.figure()\n",
    "        plt.title(f\"N = {N} - kernel_L = {kernel_L}\")\n",
    "        for regularization in regularization_lst:\n",
    "            err_vect = -1 * np.ones((len(epsilon_lst)-1))\n",
    "            for eps_i, epsilon in enumerate(epsilon_lst[1:]): \n",
    "                err_vect[eps_i] = results[N][kernel_L][regularization][epsilon]['errorinfnorm']\n",
    "                color = cmap(norm(np.log(regularization)))\n",
    "            plt.plot(epsilon_vect, err_vect, \"o-\", label=f\"$\\lambda$={regularization}\", color=color)\n",
    "        plt.xlim([0, 1])\n",
    "        plt.xlabel(\"$\\epsilon$\")\n",
    "        plt.ylabel(\"Error w.r.t $\\widehat{\\mu}$\") \n",
    "        plt.legend(loc=\"best\")\n",
    "        if save:\n",
    "            complete_path = f\"{save_path}mean_N{N}_L{kernel_L}_reglst{regularization_lst}_epslst{epsilon_lst}_{datetime.datetime.now().strftime(dateformat)}\"\n",
    "            plt.savefig(f\"{complete_path}.jpg\")\n",
    "            tkz.save(f\"{complete_path}.tex\")\n",
    "\n",
    "\n",
    "for N in N_lst:\n",
    "    for kernel_L in kernel_L_lst:\n",
    "        plt.figure()\n",
    "        plt.title(f\"N = {N} - kernel_L = {kernel_L}\")\n",
    "        for regularization in regularization_lst:\n",
    "            err_vect = -1 * np.ones((len(epsilon_lst)-1))\n",
    "            for eps_i, epsilon in enumerate(epsilon_lst[1:]): \n",
    "                err_vect[eps_i] = results[N][kernel_L][regularization][epsilon]['errorinfnormvar']\n",
    "                color = cmap(norm(np.log(regularization)))\n",
    "            plt.plot(epsilon_vect, err_vect, \"o-\", label=f\"$\\lambda$={regularization}\", color=color)\n",
    "        plt.xlim([0, 1])\n",
    "        plt.xlabel(\"$\\epsilon$\")\n",
    "        plt.ylabel(\"Error w.r.t $\\widehat{\\sigma}$\") \n",
    "        plt.legend(loc=\"best\")\n",
    "        if save:\n",
    "            complete_path = f\"{save_path}var_N{N}_L{kernel_L}_reglst{regularization_lst}_epslst{epsilon_lst}_{datetime.datetime.now().strftime(dateformat)}\"\n",
    "            plt.savefig(f\"{complete_path}.jpg\")\n",
    "            tkz.save(f\"{complete_path}.tex\")\n",
    "\n",
    "\n",
    "# reg fixed\n",
    "# forall eps forall kernel_L\n",
    "# for every lambda plot infnorm-error varying N\n",
    "\n",
    "norm = plt.Normalize(-1, np.log(max(regularization_lst)))\n",
    "cmap = cm.get_cmap(\"viridis_r\")\n",
    "\n",
    "for kernel_L in kernel_L_lst:\n",
    "    for epsilon in epsilon_lst[1:]:\n",
    "        plt.figure()\n",
    "        plt.title(f\"$\\epsilon$ = {epsilon} - kernel_L = {kernel_L}\")\n",
    "        for regularization in regularization_lst:\n",
    "            err_vect = -1 * np.ones((len(N_lst)))\n",
    "            err_vect_postvariance = -1 * np.ones((len(N_lst)))\n",
    "            for N_i, N in enumerate(N_lst): \n",
    "                err_vect[N_i] = results[N][kernel_L][regularization][epsilon]['errorinfnorm']\n",
    "                err_vect_postvariance[N_i] = results[N][kernel_L][regularization][epsilon]['errorinfnormvar']\n",
    "            plt.plot(N_vect, err_vect, \"o-\", label=f\"$\\lambda$={regularization} - mean\", color = cmap(norm(np.log(regularization))))\n",
    "            plt.plot(N_vect, err_vect_postvariance, \"^--\", label=f\"$\\lambda$={regularization} - var\", color = cmap(norm(np.log(regularization))))\n",
    "        # plt.xlim([0, 1])\n",
    "        plt.xlabel(\"$N$\")\n",
    "        plt.ylabel(\"Error w.r.t $\\widehat{\\mu}$\") \n",
    "        plt.legend(loc=\"best\")\n",
    "        if save:\n",
    "            complete_path = f\"{save_path}eps{epsilon}_L{kernel_L}_reglst{regularization_lst}_Nlst{N_lst}_{datetime.datetime.now().strftime(dateformat)}\"\n",
    "            plt.savefig(f\"{complete_path}.jpg\")\n",
    "            tkz.save(f\"{complete_path}.tex\")\n",
    "            \n",
    "\n",
    "# N/reg fixed\n",
    "# forall ratios forall kernel_L\n",
    "# for every lambda plot infnorm-error varying N\n",
    "\n",
    "symbols = ['o-', '^-']\n",
    "norm = plt.Normalize(0, max(N_lst))\n",
    "cmap = cm.get_cmap(\"viridis_r\")\n",
    "\n",
    "for kernel_L in kernel_L_lst:\n",
    "    plt.figure()\n",
    "    for ratio_i, ratio in enumerate([1/10, 1/100]):\n",
    "        # plt.title(f\"ratio N/reg = {ratio} - kernel_L = {kernel_L}\")\n",
    "        for N in N_lst:\n",
    "            err_vect = -1 * np.ones((len(epsilon_lst)-1))\n",
    "            for eps_i, epsilon in enumerate(epsilon_lst[1:]): \n",
    "                err_vect[eps_i] = results[N][kernel_L][int(N*ratio)][epsilon]['errorinfnorm']\n",
    "            color = cmap(norm(N))\n",
    "            plt.plot(epsilon_vect, err_vect, symbols[ratio_i], label=f\"$ N / \\\\lambda $={ratio} --- $ N $={N}\", color=color)\n",
    "        plt.xlabel(\"$\\\\epsilon$\")\n",
    "        plt.ylabel(\"Error w.r.t $\\\\widehat{\\\\mu}$\") \n",
    "        plt.legend(loc=\"best\")\n",
    "    if save:\n",
    "        complete_path = f\"{save_path}ratiomeans_L{kernel_L}_Nlst{N_lst}_reglst{regularization_lst}_epslst{epsilon_lst}_{datetime.datetime.now().strftime(dateformat)}\"\n",
    "        plt.savefig(f\"{complete_path}.jpg\")\n",
    "        tkz.save(f\"{complete_path}.tex\")\n",
    "\n",
    "\n",
    "for kernel_L in kernel_L_lst:\n",
    "    plt.figure()\n",
    "    for ratio_i, ratio in enumerate([1/10, 1/100]):\n",
    "        # plt.title(f\"ratio N/reg = {ratio} - kernel_L = {kernel_L}\")\n",
    "        for N in N_lst:\n",
    "            err_vect = -1 * np.ones((len(epsilon_lst)-1))\n",
    "            for eps_i, epsilon in enumerate(epsilon_lst[1:]): \n",
    "                err_vect[eps_i] = results[N][kernel_L][int(N*ratio)][epsilon]['errorinfnormvar']\n",
    "            color = cmap(norm(N))\n",
    "            plt.plot(epsilon_vect, err_vect, symbols[ratio_i], label=f\"$ N / \\\\lambda \\\\!=\\\\!{ratio}$ -- $ N \\\\!=\\\\!{N}$\", color=color)\n",
    "        plt.xlabel(\"$\\\\epsilon$\")\n",
    "        plt.ylabel(\"Error w.r.t $\\\\widehat{\\\\sigma}$\") \n",
    "        plt.legend(loc=\"best\")\n",
    "    if save:\n",
    "        complete_path = f\"{save_path}ratiovar_L{kernel_L}_Nlst{N_lst}_reglst{regularization_lst}_epslst{epsilon_lst}_{datetime.datetime.now().strftime(dateformat)}\"\n",
    "        plt.savefig(f\"{complete_path}.jpg\")\n",
    "        tkz.save(f\"{complete_path}.tex\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
